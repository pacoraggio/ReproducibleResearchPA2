---
title: "Data Processing notes"
author: "Paolo Coraggio"
date: "09/01/2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
library(lubridate) 
library(ggplot2) 
library(dplyr) 

knitr::opts_chunk$set(echo = TRUE)
```

## Synopsis

The National Oceanic and Atmospheric Administration (NOAA) is an US scientific agency that focuses on ["conditions of the oceans, major waterways, and atmosphere"](https://en.wikipedia.org/wiki/National_Oceanic_and_Atmospheric_Administration) which one of the main activity is "Monitoring and observing Earth systems with instruments and data collection networks". 
The [Storm Event Database](https://www.ncdc.noaa.gov/stormevents/details.jsp) contains data from 1950 to date that tracks the caracteristics of major weather events including an estimates of any fatalities, injuries and property damage. 

The goal of this project is to explore a subset of the Storm Event Database (from 1950 to 2011) to address the following questions:

1. Across the United States, which types of events (as indicated in the EVTYPE 
    variable) are most harmful with respect to population health?
2. Across the United States, which types of events have the greatest economic 
    consequences?

In order to address these questions, the provided .csv file has been downloaded, explored and a selected number of variables has been loaded into a dataframe. The dataframe has been further processed in order to filter the event type describing the cause of casualties//damages and then computed the sums of casualties as well as for costs grouped by event type. Finally, the result are reported using plots and tables about the top 10 harmful and costly events.

## Data Processing

This section describes how the data has been loaded into R data structures for the data analysis. The original raw data file is a zipped ~50Mb file containing an about 500Mb database and so the strategy for saving computer space (and computing time) chosen for analysing the data is to load only the variable that are necessary for answering the roposed questions.

Extracting the first lines from the .csv file gives us information about the variable it contains

```{r varnames, message=FALSE, warning=FALSE}


names <- read.csv("./Data/repdata_data_StormData.csv.bz2", 
                  nrows = 10, header = TRUE)

knitr::kable(str(names))
```


The database contains $37$ variables, in order to address the questions, the following 12 variables are extracted from the .csv file (all rows included)

- "STATE__"    
- "BGN_DATE"   
- "STATE"      
- "EVTYPE"     
- "F"          
- "MAG"       
- "FATALITIES" 
- "INJURIES"   
- "PROPDMG"    
- "PROPDMGEXP" 
- "CROPDMG"    
- "CROPDMGEXP"

With `F` and `MAG` variably possibly redundant. 

```{r loadingraw}
df.rawdata <- read.csv("./Data/repdata_data_StormData.csv.bz2",
                    colClasses = c("character", 
                                   "character", 
                                   rep("NULL",4), 
                                   rep("character",2),
                                   rep("NULL",12),
                                   "character","numeric",
                                   rep("numeric",3),
                                   "character", 
                                   "numeric", 
                                   "character", 
                                   rep("NULL",9)))

knitr::kable(head(df.rawdata))
```

After loading the raw data, the database is further reducing by considering raws where at least one fatality/injury/property or crop damage have been recorder.

```{r reducedraw}
df.rawdatared <- df.rawdata[!(df.rawdata$FATALITIES == 0 &
                              df.rawdata$INJURIES == 0 &
                              df.rawdata$PROPDMG == 0 &
                              df.rawdata$CROPDMG == 0),]

## convert Begin Date to Date format
df.rawdatared$BGN_DATE <- as.Date(sub(" .*", "", df.rawdatared$BGN_DATE), format("%m/%d/%Y"))
```

In this way the original database consisting of $902297 \times 37$ values has been pruned into a more handable $254633 \times 12$ values database.

### Selecting and merging Event Type

The [National Weather Service Storm Data Documentation](https://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf) document lists $48$ different event type (ref. section 2.1.1 for the Storm Data Event Table and Chapter 7 for event type description) while `EVTYPE` database variable contains `r length(unique(df.rawdatared$EVTYPE))` different values.  